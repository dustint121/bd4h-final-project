{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dustint121/bd4h-final-project/blob/main/BD4H_Final_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lizn_FBotAPz",
        "outputId": "1031ffd2-c114-499d-f9c1-9339eaf9246b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Working Directory: /content/gdrive/MyDrive/bd4h-final-project-data\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "Working Directory: /content/gdrive/My Drive/bd4h-final-project-data\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# View current working directory\n",
        "print(\"Current Working Directory:\", os.getcwd())\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/gdrive')\n",
        "# Change working directory to your file position\n",
        "path = \"/content/gdrive/My Drive/bd4h-final-project-data/\"\n",
        "os.chdir(path)\n",
        "\n",
        "# Confirm the change\n",
        "print(\"Working Directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "8eDlBaaqFc1s"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2D UNet Model\n"
      ],
      "metadata": {
        "id": "HEtAeDeOCPqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(131):\n",
        "  #check if file exists\n",
        "  if not os.path.exists(f\"/content/gdrive/My Drive/bd4h-final-project-data/LITS17/{i}.npz\"):\n",
        "    print(f\"{i}.npz does not exist\")\n",
        "  # else:\n",
        "  # np.load(f\"/content/gdrive/My Drive/bd4h-final-project-data/LITS17/{i}.npz\")"
      ],
      "metadata": {
        "id": "Y3ae7Mb1W6IQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Classes and Util functions for 2D UNet Model"
      ],
      "metadata": {
        "id": "gbbV8VyCCcYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "MedicalSliceDataset_2D converts 3D arrays(volumes and segmentations) into lists of 2D arrays\n",
        "\n",
        "In model training/testing:\n",
        "    self.volumes = inputs\n",
        "    self.segmentations = targets\n",
        "\"\"\"\n",
        "class MedicalSliceDataset_2D(Dataset):\n",
        "    def __init__(self, dataset_path, file_indices, max_slices=512):\n",
        "        self.volumes = [] #will be a list of 2D arrays\n",
        "        self.segmentations = [] #will be a list of 2D arrays\n",
        "\n",
        "\n",
        "        for count, i in enumerate(file_indices):\n",
        "            print(f\"Loading file {count+1}/{len(file_indices)}\")\n",
        "            data = np.load(f\"{dataset_path}/{i}.npz\")\n",
        "            volume, seg = None, None\n",
        "            if \"LITS17\" in dataset_path:\n",
        "                volume = data[\"volume\"]\n",
        "                seg = data[\"segmentation\"]\n",
        "            elif \"KITS19\" in dataset_path:\n",
        "                volume = np.transpose(data[\"volume\"], (1, 2, 0))\n",
        "                seg = np.transpose(data[\"segmentation\"], (1, 2, 0))\n",
        "\n",
        "            # Per-volume min-max normalization (prevents data leakage)\n",
        "            # volume = (volume - volume.min()) / (volume.max() - volume.min() + 1e-8)\n",
        "\n",
        "            #Using z-score\n",
        "            volume = (volume - volume.mean()) / (volume.std() + 1e-8)\n",
        "\n",
        "            # Add all slices as individual samples\n",
        "            for d in range(volume.shape[2]): #for each layer of \"depth\"\n",
        "                self.volumes.append(volume[..., d]) #add the \"height x weight\" 2D data of the layer to the self.volume\n",
        "                self.segmentations.append(seg[..., d])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.volumes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Remove channel dim from masks & convert to int64\n",
        "        slice = torch.FloatTensor(self.volumes[idx][None, ...])  # (1,512,512)\n",
        "        mask = torch.LongTensor(self.segmentations[idx])  # (512,512) NOT (1,512,512)\n",
        "        return slice, mask\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "DoubleConv:\n",
        "Strenghts:\n",
        "Deeper Feature Extraction: Two convolutional layers instead of one (like in ConvNet),\n",
        "                            enabling richer hierarchical feature learning.\n",
        "Instance Normalization: Better for medical imaging with small batch sizes compared to batch norm.\n",
        "Leaky ReLU: Avoids \"dead neurons\" by allowing small gradients for negative inputs (unlike basic ReLU in ConvNet).\n",
        "\n",
        "Weaknesses:\n",
        "Higher computational cost due to dual convolutions.\n",
        "Requires more memory for intermediate feature maps.\n",
        "\"\"\"\n",
        "class DoubleConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet2D(nn.Module):\n",
        "    def __init__(self, n_channels=1, n_classes=3):\n",
        "        super().__init__()\n",
        "        self.inc = DoubleConv(n_channels, 32)\n",
        "        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(32, 64))\n",
        "        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(64, 128))\n",
        "        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv(128, 256))\n",
        "        self.up1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.conv1 = DoubleConv(256, 128)\n",
        "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.conv2 = DoubleConv(128, 64)\n",
        "        self.up3 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
        "        self.conv3 = DoubleConv(64, 32)\n",
        "        self.outc = nn.Conv2d(32, n_classes, kernel_size=1)  # Output 3 channels\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input shape: (batch_size, channels, height, width)\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "\n",
        "        x = self.up1(x4)\n",
        "        x = torch.cat([x, x3], dim=1)\n",
        "        x = self.conv1(x)\n",
        "        x = self.up2(x)\n",
        "        x = torch.cat([x, x2], dim=1)\n",
        "        x = self.conv2(x)\n",
        "        x = self.up3(x)\n",
        "        x = torch.cat([x, x1], dim=1)\n",
        "        x = self.conv3(x)\n",
        "        return self.outc(x)"
      ],
      "metadata": {
        "id": "O4AkV4tCCbey"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dice_score(pred, target):\n",
        "    smooth = 1e-6\n",
        "    pred = F.softmax(pred, dim=1)\n",
        "    scores = []\n",
        "    # Calculate Dice for each class (background, organ, tumor)\n",
        "    for class_idx in range(3):\n",
        "        pred_mask = pred[:, class_idx]  # Get probability maps for this class\n",
        "        target_mask = (target == class_idx).float()\n",
        "\n",
        "        intersection = (pred_mask * target_mask).sum()\n",
        "        union = pred_mask.sum() + target_mask.sum()\n",
        "        scores.append((2. * intersection + smooth) / (union + smooth))\n",
        "\n",
        "    return torch.mean(torch.stack(scores))  # Return mean Dice across classes\n",
        "\n",
        "\n",
        "# Additional helper function for class-wise Dice reporting\n",
        "def dice_score_per_class(pred, target):\n",
        "    smooth = 1e-6\n",
        "    pred = F.softmax(pred, dim=1).argmax(1)\n",
        "    scores = []\n",
        "    for class_idx in range(3):\n",
        "        pred_mask = (pred == class_idx).float()\n",
        "        target_mask = (target == class_idx).float()\n",
        "        intersection = (pred_mask * target_mask).sum()\n",
        "        union = pred_mask.sum() + target_mask.sum()\n",
        "        scores.append((2.*intersection + smooth)/(union + smooth))\n",
        "    return scores\n",
        "\n",
        "\n",
        "def hybrid_loss(pred, target):\n",
        "    # Cross Entropy\n",
        "    ce = F.cross_entropy(pred, target)\n",
        "\n",
        "    # Dice Loss (1 - mean Dice score)\n",
        "    dice_loss = 1 - dice_score(pred, target)\n",
        "\n",
        "    return ce + dice_loss  # Paper's λ=1 for both terms"
      ],
      "metadata": {
        "id": "v2l0C-fyGjjV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Testing Here"
      ],
      "metadata": {
        "id": "MH4g2VmNCix1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Lits Dataset wrapper\n",
        "\n",
        "# volume_indices = list(range(131))  # All LITS17 volumes\n",
        "volume_indices = list(range(5)) #test small subset\n",
        "\n",
        "# data files with irregular data\n",
        "# lits_17_list = [0, 1, 4, 16, 17, 18, 22, 35, 37, 38, 48, 50, 52, 53, 54, 55, 57, 63, 65, 68, 69, 70, 71, 72, 74, 76, 77,\n",
        "#                 78, 80, 81, 82, 87, 88, 89, 90, 91, 92, 93, 95, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117]\n",
        "\n",
        "# kits_19_list = [15, 18, 19, 23, 25, 31, 32, 40, 43, 45, 48, 50, 61, 64, 65, 66, 81, 85, 86, 94, 97, 99, 107, 109, 111, 117,\n",
        "#                 121, 123, 124, 128, 131, 133, 150, 163, 166, 167, 168, 169, 172, 180, 185, 191, 192, 193, 194, 199, 202]\n",
        "\n",
        "# for i in lits_17_list:\n",
        "#   volume_indices.remove(i)\n",
        "\n",
        "train_volumes, test_volumes = train_test_split(volume_indices, test_size=0.2, random_state=42)\n",
        "\n",
        "lits_training_dataset = MedicalSliceDataset_2D(\"/content/gdrive/My Drive/bd4h-final-project-data/LITS17\", file_indices = train_volumes)\n",
        "lits_testing_dataset = MedicalSliceDataset_2D(\"/content/gdrive/My Drive/bd4h-final-project-data/LITS17\", file_indices = test_volumes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JoqrZKdUvR_C",
        "outputId": "91e1b377-33fa-46f2-8386-0f91be654159"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading file 1/4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/numpy/core/_methods.py:152: RuntimeWarning: overflow encountered in reduce\n",
            "  arrmean = umr_sum(arr, axis, dtype, keepdims=True, where=where)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading file 2/4\n",
            "Loading file 3/4\n",
            "Loading file 4/4\n",
            "Loading file 1/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#20 minutes\n",
        "\n",
        "data_path = \"/content/gdrive/My Drive/bd4h-final-project-data/\"\n",
        "\n",
        "\n",
        "train_loader = DataLoader(lits_training_dataset, batch_size=16, shuffle=True,\n",
        "                                                  pin_memory=True, num_workers=12, persistent_workers=True)\n",
        "\n",
        "test_loader = DataLoader(lits_testing_dataset, batch_size=16, shuffle=True, pin_memory=True, num_workers=12, persistent_workers=True)\n",
        "\n",
        "\n",
        "# train_loader = DataLoader(lits_training_dataset, batch_size=16, shuffle=True, pin_memory=True)\n",
        "\n",
        "# test_loader = DataLoader(lits_testing_dataset, batch_size=16, shuffle=True, pin_memory=True)\n"
      ],
      "metadata": {
        "id": "iQ7jrJykF7C1"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = UNet2D(n_channels=1, n_classes=3)\n",
        "# criterion = hybrid_loss\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.99)\n",
        "\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "# #use gpu if available\n",
        "# model.to(device)\n",
        "\n",
        "# # Training Loop with Class-wise Dice Reporting\n",
        "# best_dice = 0\n",
        "# for epoch in range(500):\n",
        "#     # Training\n",
        "#     model.train()\n",
        "#     print(len(train_loader))\n",
        "#     for inputs, targets in train_loader:\n",
        "#         inputs = inputs.to(device)  # Add this\n",
        "#         targets = targets.to(device).squeeze(1)  # Add this\n",
        "#         # print(\"training\")\n",
        "#         optimizer.zero_grad()\n",
        "#         outputs = model(inputs)\n",
        "#         loss = hybrid_loss(outputs, targets.squeeze(1))  # Remove channel dim from targets\n",
        "#         loss.backward()\n",
        "#         optimizer.step()\n",
        "\n",
        "#     # Validation\n",
        "#     model.eval()\n",
        "#     test_dice = 0\n",
        "#     class_dice = [0, 0, 0]  # [Background, Organ, Tumor]\n",
        "\n",
        "\n",
        "#     with torch.no_grad():\n",
        "#         for inputs, targets in test_loader:\n",
        "#             inputs = inputs.to(device)  # Add this\n",
        "#             targets = targets.to(device).squeeze(1)  # Add this\n",
        "#             outputs = model(inputs)\n",
        "#             batch_scores = dice_score_per_class(outputs, targets.squeeze(1))\n",
        "#             for i in range(3):\n",
        "#                 class_dice[i] += batch_scores[i]\n",
        "\n",
        "#     # Calculate average Dice per class\n",
        "#     avg_dice = [c/len(test_loader) for c in class_dice]\n",
        "#     print(f\"Epoch {epoch+1}\")\n",
        "#     print(f\"Liver Dice: {avg_dice[1]:.4f}, Tumor Dice: {avg_dice[2]:.4f}, Mean Dice: {torch.mean(torch.tensor(avg_dice)):.4f}\")\n",
        "\n",
        "#     # Save best model based on tumor Dice (most clinically relevant)\n",
        "#     if avg_dice[2] > best_dice:\n",
        "#         best_dice = avg_dice[2]\n",
        "#         torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "# print(f\"\\nBest Tumor Dice: {best_dice*100:.2f}%\")"
      ],
      "metadata": {
        "id": "j5ldXmbFGoEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet2D(n_channels=1, n_classes=3)\n",
        "criterion = hybrid_loss\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.99)\n",
        "\n",
        "\n",
        "#use gpu if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "best_dice = 0\n",
        "\n",
        "\n",
        "#10 minutes per epoch for full dataset\n",
        "for epoch in range(500):\n",
        "    print(f\"\\nEpoch {epoch+1}/500\")\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "\n",
        "    # Training with tqdm progress bar\n",
        "    with tqdm(train_loader, desc=\"Training\", leave=False) as pbar:\n",
        "        for inputs, targets in pbar:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device).squeeze(1)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = hybrid_loss(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    print(f\"  Train loss: {sum(train_losses)/len(train_losses):.4f}\")\n",
        "\n",
        "    # Validation with tqdm progress bar\n",
        "    model.eval()\n",
        "    class_dice = [0.0, 0.0, 0.0]\n",
        "    with torch.no_grad():\n",
        "        with tqdm(test_loader, desc=\"Validation\", leave=False) as pbar:\n",
        "            for inputs, targets in pbar:\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device).squeeze(1)\n",
        "                outputs = model(inputs)\n",
        "                batch_scores = dice_score_per_class(outputs, targets)\n",
        "                for i in range(3):\n",
        "                    class_dice[i] += batch_scores[i]\n",
        "\n",
        "    avg_dice = [c/len(test_loader) for c in class_dice]\n",
        "    mean_dice = sum(avg_dice) / len(avg_dice)\n",
        "    print(f\"  Dice - Background: {avg_dice[0]:.4f}, Organ: {avg_dice[1]:.4f}, Tumor: {avg_dice[2]:.4f}, Mean: {mean_dice:.4f}\")\n",
        "\n",
        "    # Save best model based on tumor Dice (class 2)\n",
        "    if avg_dice[2] > best_dice:\n",
        "        best_dice = avg_dice[2]\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "print(f\"\\nBest Tumor Dice: {best_dice*100:.2f}%\")\n"
      ],
      "metadata": {
        "id": "wCuR1uAHnfYG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3D UNet Model"
      ],
      "metadata": {
        "id": "5HJQNdHh_eFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "RZ2GuSgGFBEa"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(torch.cuda.memory_allocated(device=device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clllWIFHF7NN",
        "outputId": "542ca8f4-699d-45ed-f1fd-2e614508d48c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "free_memory, total_memory = torch.cuda.mem_get_info(device=device)\n",
        "print(f\"Free GPU memory: {free_memory} bytes\")\n",
        "print(f\"Total GPU memory: {total_memory} bytes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq5MCK0PGDYh",
        "outputId": "21f4823e-a51e-4c01-fa89-6dc00f5c6f9c"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Free GPU memory: 9306112 bytes\n",
            "Total GPU memory: 42474471424 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes and Util functions for 3D UNet Model"
      ],
      "metadata": {
        "id": "EM5I6Kih_l14"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MedicalVolumeDataset_3D(Dataset):\n",
        "    def __init__(self, dataset_path, file_indices):\n",
        "        self.volumes = []\n",
        "        self.segmentations = []\n",
        "\n",
        "        for i in file_indices:\n",
        "            data = np.load(f\"{dataset_path}/{i}.npz\")\n",
        "\n",
        "            if \"LITS17\" in dataset_path:\n",
        "                volume = data[\"volume\"]  # (H, W, D)\n",
        "                seg = data[\"segmentation\"]\n",
        "                # Reorder to (D, H, W)\n",
        "                volume = np.transpose(volume, (2, 0, 1)).astype(np.int32)\n",
        "                seg = np.transpose(seg, (2, 0, 1))\n",
        "            elif \"KITS19\" in dataset_path:\n",
        "                volume = data[\"volume\"].astype(np.int32)  # (D, H, W)\n",
        "                seg = data[\"segmentation\"]\n",
        "\n",
        "            # Z-score normalization (paper Section 4.1)\n",
        "            volume = self._normalize(volume, seg)\n",
        "\n",
        "            self.volumes.append(volume[None, ...])  # Add channel dim\n",
        "            self.segmentations.append(seg)\n",
        "\n",
        "    def _normalize(self, volume, seg):\n",
        "        \"\"\"Paper-style normalization using foreground voxels\"\"\"\n",
        "        mask = seg > 0\n",
        "        if mask.sum() == 0:  # Handle empty masks\n",
        "            return volume\n",
        "        mean = volume[mask].mean()\n",
        "        std = volume[mask].std()\n",
        "        return (volume - mean) / (std + 1e-8)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.volumes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        volume = torch.FloatTensor(self.volumes[idx])  # (1, D, H, W)\n",
        "        seg = torch.LongTensor(self.segmentations[idx])  # (D, H, W)\n",
        "\n",
        "        # Pad all spatial dims to multiples of 8\n",
        "        d, h, w = volume.shape[1], volume.shape[2], volume.shape[3]\n",
        "        pad_d = (8 - (d % 8)) % 8\n",
        "        pad_h = (8 - (h % 8)) % 8\n",
        "        pad_w = (8 - (w % 8)) % 8\n",
        "\n",
        "        volume_padded = F.pad(volume, (0, pad_w, 0, pad_h, 0, pad_d, 0, 0))  # (1, D+pd, H+ph, W+pw)\n",
        "        seg_padded = F.pad(seg, (0, pad_w, 0, pad_h, 0, pad_d))  # (D+pd, H+ph, W+pw)\n",
        "        return volume_padded, seg_padded\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class DoubleConv3D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.InstanceNorm3d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.InstanceNorm3d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class UNet3D(nn.Module):\n",
        "    def __init__(self, n_channels=1, n_classes=3):\n",
        "        super().__init__()\n",
        "        # Encoder\n",
        "        self.inc = DoubleConv3D(n_channels, 32)\n",
        "        self.down1 = nn.Sequential(nn.MaxPool3d(2), DoubleConv3D(32, 64))\n",
        "        self.down2 = nn.Sequential(nn.MaxPool3d(2), DoubleConv3D(64, 128))\n",
        "        self.down3 = nn.Sequential(nn.MaxPool3d(2), DoubleConv3D(128, 256))\n",
        "\n",
        "\n",
        "        # Decoder (Fixed with output_padding)\n",
        "        self.up1 = nn.ConvTranspose3d(256, 128, kernel_size=2, stride=2)\n",
        "        self.conv1 = DoubleConv3D(256, 128)  # 128 + 128 = 256\n",
        "        self.up2 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2)\n",
        "        self.conv2 = DoubleConv3D(128, 64)   # 64 + 64 = 128\n",
        "        self.up3 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2)\n",
        "        self.conv3 = DoubleConv3D(64, 32)    # 32 + 32 = 64\n",
        "\n",
        "        self.outc = nn.Conv3d(32, n_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Encoder\n",
        "        print(\"here\")\n",
        "        x1 = self.inc(x)    # (B,32,D,H,W)\n",
        "        x2 = self.down1(x1) # (B,64,D/2,H/2,W/2)\n",
        "        x3 = self.down2(x2) # (B,128,D/4,H/4,W/4)\n",
        "        x4 = self.down3(x3) # (B,256,D/8,H/8,W/8)\n",
        "\n",
        "        # Decoder\n",
        "        x = self.up1(x4)    # (B,128,D/4,H/4,W/4)\n",
        "        x = torch.cat([x, x3], dim=1)  # (B,256,D/4,H/4,W/4)\n",
        "        x = self.conv1(x)   # (B,128,D/4,H/4,W/4)\n",
        "\n",
        "        x = self.up2(x)     # (B,64,D/2,H/2,W/2)\n",
        "        x = torch.cat([x, x2], dim=1)  # (B,128,D/2,H/2,W/2)\n",
        "        x = self.conv2(x)   # (B,64,D/2,H/2,W/2)\n",
        "\n",
        "        x = self.up3(x)     # (B,32,D,H,W)\n",
        "        x = torch.cat([x, x1], dim=1)  # (B,64,D,H,W)\n",
        "        x = self.conv3(x)   # (B,32,D,H,W)\n",
        "\n",
        "        return self.outc(x)  # (B,n_classes,D,H,W)"
      ],
      "metadata": {
        "id": "QXX5JaUN_jyZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hybrid Loss (CE + Dice)\n",
        "def hybrid_loss(pred, target):\n",
        "    ce = F.cross_entropy(pred, target)\n",
        "    pred_prob = F.softmax(pred, dim=1)\n",
        "    dice = 1 - dice_score_3d(pred_prob, target)\n",
        "    return ce + dice\n",
        "\n",
        "# 3D Dice Calculation\n",
        "def dice_score_3d(pred, target):\n",
        "    smooth = 1e-6\n",
        "    pred = pred.argmax(1)\n",
        "    scores = []\n",
        "    for class_idx in range(3):\n",
        "        pred_mask = (pred == class_idx).float()\n",
        "        target_mask = (target == class_idx).float()\n",
        "        intersection = (pred_mask * target_mask).sum()\n",
        "        union = pred_mask.sum() + target_mask.sum()\n",
        "        scores.append((2.*intersection + smooth)/(union + smooth))\n",
        "    return torch.mean(torch.tensor(scores))"
      ],
      "metadata": {
        "id": "iLUWufp-A1rp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Testing Here"
      ],
      "metadata": {
        "id": "6YXZinyyhfdJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# volume_indices = list(range(131))  # All LITS17 volumes\n",
        "volume_indices = list(range(2)) #test small subset\n",
        "\n",
        "# data files with irregular data\n",
        "# lits_17_list = [0, 1, 4, 16, 17, 18, 22, 35, 37, 38, 48, 50, 52, 53, 54, 55, 57, 63, 65, 68, 69, 70, 71, 72, 74, 76, 77,\n",
        "#                 78, 80, 81, 82, 87, 88, 89, 90, 91, 92, 93, 95, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 117]\n",
        "\n",
        "# kits_19_list = [15, 18, 19, 23, 25, 31, 32, 40, 43, 45, 48, 50, 61, 64, 65, 66, 81, 85, 86, 94, 97, 99, 107, 109, 111, 117,\n",
        "#                 121, 123, 124, 128, 131, 133, 150, 163, 166, 167, 168, 169, 172, 180, 185, 191, 192, 193, 194, 199, 202]\n",
        "\n",
        "# for i in lits_17_list:\n",
        "#   volume_indices.remove(i)\n",
        "\n",
        "train_volumes, test_volumes = train_test_split(volume_indices, test_size=0.2, random_state=42)\n",
        "\n",
        "training_dataset = MedicalVolumeDataset_3D(\"/content/gdrive/My Drive/bd4h-final-project-data/LITS17\", file_indices = train_volumes)\n",
        "testing_dataset = MedicalVolumeDataset_3D(\"/content/gdrive/My Drive/bd4h-final-project-data/LITS17\", file_indices = test_volumes)"
      ],
      "metadata": {
        "id": "JXolFJSm_ufw"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_loader = DataLoader(\n",
        "    training_dataset,\n",
        "    batch_size=2,  # Matches paper's LiTS batch size\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# test_loader = DataLoader(\n",
        "#     test_dataset,\n",
        "#     batch_size=2,  # Matches paper's LiTS batch size\n",
        "#     shuffle=True,\n",
        "#     num_workers=4,\n",
        "#     pin_memory=True\n",
        "# )\n",
        "test_loader = DataLoader(\n",
        "    testing_dataset,\n",
        "    batch_size=2,  # Matches paper's LiTS batch size\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "NzGFR1SrALaC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = UNet3D(n_channels=1, n_classes=3)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.99)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "best_dice = 0\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(500):\n",
        "    print(f\"\\nEpoch {epoch+1}/500\")\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "\n",
        "    # Training with tqdm progress bar\n",
        "    with tqdm(train_loader, desc=\"Training\", leave=False) as pbar:\n",
        "        for inputs, targets in pbar:\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device).squeeze(1)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = hybrid_loss(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_losses.append(loss.item())\n",
        "            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    print(f\"  Train loss: {sum(train_losses)/len(train_losses):.4f}\")\n",
        "\n",
        "    # Validation with tqdm progress bar\n",
        "    model.eval()\n",
        "    class_dice = [0.0, 0.0, 0.0]\n",
        "    with torch.no_grad():\n",
        "        with tqdm(test_loader, desc=\"Validation\", leave=False) as pbar:\n",
        "            for inputs, targets in pbar:\n",
        "                inputs = inputs.to(device)\n",
        "                targets = targets.to(device).squeeze(1)\n",
        "                outputs = model(inputs)\n",
        "                batch_scores = dice_score_3d(outputs, targets)\n",
        "                for i in range(3):\n",
        "                    class_dice[i] += batch_scores[i]\n",
        "\n",
        "    avg_dice = [c/len(test_loader) for c in class_dice]\n",
        "    mean_dice = sum(avg_dice) / len(avg_dice)\n",
        "    print(f\"  Dice - Background: {avg_dice[0]:.4f}, Organ: {avg_dice[1]:.4f}, Tumor: {avg_dice[2]:.4f}, Mean: {mean_dice:.4f}\")\n",
        "\n",
        "    # Save best model based on tumor Dice (class 2)\n",
        "    if avg_dice[2] > best_dice:\n",
        "        best_dice = avg_dice[2]\n",
        "        torch.save(model.state_dict(), \"best_model.pth\")\n",
        "\n",
        "print(f\"\\nBest Tumor Dice: {best_dice*100:.2f}%\")"
      ],
      "metadata": {
        "id": "TMTKh7CMAwBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2-5D UNet Model"
      ],
      "metadata": {
        "id": "D_-4WU76g9ZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes and Util functions for 2-5D UNet Model"
      ],
      "metadata": {
        "id": "KgJQUMl9hEdY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MedicalVolumeDataset2_5D(Dataset):\n",
        "    def __init__(self, dataset_path, file_indices, num_slices=3):\n",
        "        self.num_slices = num_slices\n",
        "        self.half_slices = num_slices // 2\n",
        "        self.volumes = []\n",
        "        self.segmentations = []\n",
        "\n",
        "        for i in file_indices:\n",
        "            data = np.load(f\"{dataset_path}/{i}.npz\")\n",
        "            volume, seg = None, None\n",
        "            # volume = np.transpose(data[\"volume\"], (2, 0, 1))  # (D, H, W)\n",
        "            # seg = np.transpose(data[\"segmentation\"], (2, 0, 1))\n",
        "            if \"LITS17\" in dataset_path:\n",
        "                volume = data[\"volume\"]  # (H, W, D)\n",
        "                seg = data[\"segmentation\"]\n",
        "                # Reorder to (D, H, W)\n",
        "                volume = np.transpose(volume, (2, 0, 1)).astype(np.int32)\n",
        "                seg = np.transpose(seg, (2, 0, 1))\n",
        "            elif \"KITS19\" in dataset_path:\n",
        "                volume = data[\"volume\"].astype(np.int32)  # (D, H, W)\n",
        "                seg = data[\"segmentation\"]\n",
        "\n",
        "            # Normalize using foreground voxels\n",
        "            volume = self._normalize(volume, seg)\n",
        "\n",
        "            self.volumes.append(volume)\n",
        "            self.segmentations.append(seg)\n",
        "\n",
        "    def _normalize(self, volume, seg):\n",
        "        mask = seg > 0\n",
        "        if mask.sum() == 0:\n",
        "            return volume\n",
        "        mean = volume[mask].mean()\n",
        "        std = volume[mask].std()\n",
        "        return (volume - mean) / (std + 1e-8)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.volumes)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        volume = self.volumes[idx]  # (D, H, W)\n",
        "        seg = self.segmentations[idx]\n",
        "\n",
        "        # Create 2.5D slices with adjacent slices as channels\n",
        "        slices = []\n",
        "        masks = []\n",
        "        for z in range(volume.shape[0]):\n",
        "            # Handle edge cases by replicating first/last slice\n",
        "            start = max(0, z - self.half_slices)\n",
        "            end = min(volume.shape[0], z + self.half_slices + 1)\n",
        "            slice_stack = []\n",
        "\n",
        "            # Pad with replicated slices if needed\n",
        "            while len(slice_stack) < self.num_slices:\n",
        "                if start < 0:\n",
        "                    slice_stack.append(volume[0])\n",
        "                    start += 1\n",
        "                elif end >= volume.shape[0]:\n",
        "                    slice_stack.append(volume[-1])\n",
        "                    end -= 1\n",
        "                else:\n",
        "                    slice_stack.append(volume[start])\n",
        "                    start += 1\n",
        "\n",
        "            slice_stack = np.stack(slice_stack)  # (C, H, W)\n",
        "            slices.append(slice_stack)\n",
        "            masks.append(seg[z])  # Current slice mask\n",
        "\n",
        "        volume_2_5d = np.stack(slices)  # (D, C, H, W)\n",
        "        masks = np.stack(masks)         # (D, H, W)\n",
        "\n",
        "        return torch.FloatTensor(volume_2_5d), torch.LongTensor(masks)\n",
        "\n",
        "class DoubleConv2D(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.double_conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.InstanceNorm2d(out_channels),\n",
        "            nn.LeakyReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.double_conv(x)\n",
        "\n",
        "class UNet2_5D(nn.Module):\n",
        "    def __init__(self, in_channels=3, n_classes=3):\n",
        "        super().__init__()\n",
        "        # Encoder\n",
        "        self.inc = DoubleConv2D(in_channels, 32)\n",
        "        self.down1 = nn.Sequential(nn.MaxPool2d(2), DoubleConv2D(32, 64))\n",
        "        self.down2 = nn.Sequential(nn.MaxPool2d(2), DoubleConv2D(64, 128))\n",
        "        self.down3 = nn.Sequential(nn.MaxPool2d(2), DoubleConv2D(128, 256))\n",
        "\n",
        "        # Decoder\n",
        "        self.up1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.conv1 = DoubleConv2D(256, 128)\n",
        "        self.up2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.conv2 = DoubleConv2D(128, 64)\n",
        "        self.up3 = nn.ConvTranspose2d(64, 32, kernel_size=2, stride=2)\n",
        "        self.conv3 = DoubleConv2D(64, 32)\n",
        "\n",
        "        self.outc = nn.Conv2d(32, n_classes, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: (B, C, H, W)\n",
        "        x1 = self.inc(x)    # (B,32,H,W)\n",
        "        x2 = self.down1(x1) # (B,64,H/2,W/2)\n",
        "        x3 = self.down2(x2) # (B,128,H/4,W/4)\n",
        "        x4 = self.down3(x3) # (B,256,H/8,W/8)\n",
        "\n",
        "        x = self.up1(x4)    # (B,128,H/4,W/4)\n",
        "        x = torch.cat([x, x3], dim=1) # (B,256,H/4,W/4)\n",
        "        x = self.conv1(x)   # (B,128,H/4,W/4)\n",
        "\n",
        "        x = self.up2(x)     # (B,64,H/2,W/2)\n",
        "        x = torch.cat([x, x2], dim=1) # (B,128,H/2,W/2)\n",
        "        x = self.conv2(x)   # (B,64,H/2,W/2)\n",
        "\n",
        "        x = self.up3(x)     # (B,32,H,W)\n",
        "        x = torch.cat([x, x1], dim=1) # (B,64,H,W)\n",
        "        x = self.conv3(x)   # (B,32,H,W)\n",
        "\n",
        "        return self.outc(x) # (B,n_classes,H,W)\n",
        "\n"
      ],
      "metadata": {
        "id": "IcXmKDwDhBzF"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def hybrid_loss(pred, target):\n",
        "    ce = F.cross_entropy(pred, target)\n",
        "    pred_prob = F.softmax(pred, dim=1)\n",
        "    dice = 1 - dice_score_2d(pred_prob, target)\n",
        "    return ce + dice\n",
        "\n",
        "def dice_score_2d(pred, target):\n",
        "    smooth = 1e-6\n",
        "    pred = pred.argmax(1)\n",
        "    scores = []\n",
        "    for class_idx in range(3):\n",
        "        pred_mask = (pred == class_idx).float()\n",
        "        target_mask = (target == class_idx).float()\n",
        "        intersection = (pred_mask * target_mask).sum()\n",
        "        union = pred_mask.sum() + target_mask.sum()\n",
        "        scores.append((2.*intersection + smooth)/(union + smooth))\n",
        "    return scores  # Return list of scores instead of mean"
      ],
      "metadata": {
        "id": "c2ADZ6o1hM_t"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Testing Here"
      ],
      "metadata": {
        "id": "M4b3-H9rhkPK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training setup\n",
        "volume_indices = list(range(2)) #test small subset\n",
        "\n",
        "\n",
        "train_volumes, test_volumes = train_test_split(volume_indices, test_size=0.2, random_state=42)\n",
        "\n",
        "train_dataset = MedicalVolumeDataset2_5D(\"/content/gdrive/My Drive/bd4h-final-project-data/LITS17\", file_indices = train_volumes)\n",
        "test_dataset = MedicalVolumeDataset2_5D(\"/content/gdrive/My Drive/bd4h-final-project-data/LITS17\", file_indices = test_volumes)"
      ],
      "metadata": {
        "id": "px5bf2oFhn0A"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True)"
      ],
      "metadata": {
        "id": "w-HY7ZJUh2w0"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet2_5D(in_channels=3, n_classes=3).to(device)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.99)\n",
        "\n",
        "for epoch in range(500):\n",
        "    model.train()\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Training with progress bar\n",
        "    with tqdm(train_loader, desc=f\"Epoch {epoch+1}/500 [Train]\", leave=False) as pbar:\n",
        "        for batch_idx, (data, targets) in enumerate(pbar):\n",
        "            # Flatten slices into batch dimension\n",
        "            batch_size, num_slices, channels, height, width = data.shape\n",
        "            data = data.view(-1, channels, height, width).to(device)\n",
        "            targets = targets.view(-1, height, width).to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(data)\n",
        "            loss = hybrid_loss(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update progress bar\n",
        "            epoch_loss += loss.item()\n",
        "            pbar.set_postfix({\"loss\": f\"{loss.item():.4f}\"})\n",
        "\n",
        "    # Validation with progress bar\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        class_dice = [0.0, 0.0, 0.0]  # [background, organ, tumor]\n",
        "        with tqdm(test_loader, desc=f\"Epoch {epoch+1}/500 [Val]\", leave=False) as pbar:\n",
        "            for data, targets in pbar:\n",
        "                data = data.view(-1, 3, height, width).to(device)\n",
        "                targets = targets.view(-1, height, width).to(device)\n",
        "                outputs = model(data)\n",
        "\n",
        "                batch_scores = dice_score_2d(outputs, targets)\n",
        "                for i in range(3):\n",
        "                    class_dice[i] += batch_scores[i]\n",
        "\n",
        "                pbar.set_postfix({\n",
        "                    \"bg\": f\"{batch_scores[0]:.2f}\",\n",
        "                    \"organ\": f\"{batch_scores[1]:.2f}\",\n",
        "                    \"tumor\": f\"{batch_scores[2]:.2f}\"\n",
        "                })\n",
        "\n",
        "        # Calculate averages\n",
        "        avg_dice = [c/len(test_loader) for c in class_dice]\n",
        "        mean_dice = sum(avg_dice) / len(avg_dice)\n",
        "        print(f\"Epoch {epoch+1} \\t Loss: {epoch_loss/len(train_loader):.4f}\")\n",
        "        print(f\"  Dice - Background: {avg_dice[0]:.4f}, Organ: {avg_dice[1]:.4f}, Tumor: {avg_dice[2]:.4f}, Mean: {mean_dice:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "mAe3aEQlh1i9",
        "outputId": "c3cf4dda-bcf3-4bee-9cd9-a4e8eed19a88"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": []
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 4.69 GiB. GPU 0 has a total capacity of 39.56 GiB of which 3.48 GiB is free. Process 43262 has 36.07 GiB memory in use. Of the allocated memory 33.98 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b777cc28d88c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhybrid_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-7eba85b28820>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m     \u001b[0;31m# (B,32,H,W)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (B,64,H,W)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# (B,32,H,W)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.69 GiB. GPU 0 has a total capacity of 39.56 GiB of which 3.48 GiB is free. Process 43262 has 36.07 GiB memory in use. Of the allocated memory 33.98 GiB is allocated by PyTorch, and 1.60 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "collapsed_sections": [
        "HEtAeDeOCPqZ",
        "gbbV8VyCCcYJ",
        "EM5I6Kih_l14"
      ],
      "authorship_tag": "ABX9TyMzfsYf98Qfnk+crHGXN7tv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}